#!/usr/bin/env python3
"""
Complete libffi Immunity Verification System
Tests all defensive layers and demonstrates robustness
"""

import os
import json
import subprocess
from datetime import datetime

def verify_system_dependencies():
    """Test 1: Verify system dependency installation capability"""
    print("üõ°Ô∏è LAYER 1: System Dependencies Verification")
    print("-" * 50)
    
    required_packages = [
        'libltdl7-dev',
        'libtool', 
        'autoconf',
        'automake',
        'm4'
    ]
    
    results = {}
    for package in required_packages:
        try:
            # Check if package is available in apt
            result = subprocess.run(['apt-cache', 'show', package], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                print(f"‚úÖ {package}: Available for installation")
                results[package] = "available"
            else:
                print(f"‚ùå {package}: Not found in repositories")
                results[package] = "missing"
        except Exception as e:
            print(f"‚ö†Ô∏è {package}: Error checking - {e}")
            results[package] = "error"
    
    success_rate = len([v for v in results.values() if v == "available"]) / len(required_packages)
    print(f"\nüìä System dependency availability: {success_rate*100:.1f}%")
    return results

def verify_patch_scripts():
    """Test 2: Verify patch script completeness"""
    print("\nüîß LAYER 2: Patch Scripts Verification")
    print("-" * 50)
    
    critical_files = {
        'patches/fix_libffi_autoconf.sh': 'Comprehensive autoconf fix',
        'scripts/patch_libffi.sh': 'Modular libffi patch',
        'custom_recipes/libffi/__init__.py': 'Custom recipe override'
    }
    
    results = {}
    for file_path, description in critical_files.items():
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            print(f"‚úÖ {description}: {file_path} ({file_size} bytes)")
            results[file_path] = {"status": "present", "size": file_size}
        else:
            print(f"‚ùå {description}: {file_path} MISSING")
            results[file_path] = {"status": "missing", "size": 0}
    
    present_count = len([r for r in results.values() if r["status"] == "present"])
    print(f"\nüìä Critical files present: {present_count}/{len(critical_files)}")
    return results

def verify_mutation_intelligence():
    """Test 3: Verify mutation layer intelligence"""
    print("\nüß† LAYER 3: Mutation Intelligence Verification")
    print("-" * 50)
    
    mutation_file = 'mutation_layers/patch_libffi_comprehensive.yaml'
    if os.path.exists(mutation_file):
        with open(mutation_file, 'r') as f:
            content = f.read()
        
        intelligence_indicators = [
            'error_signature: LT_SYS_SYMBOL_USCORE',
            'confidence: 0.98',
            'comprehensive_fix',
            'system_dependencies',
            'custom_recipe_created: true'
        ]
        
        found_indicators = []
        for indicator in intelligence_indicators:
            if indicator in content:
                print(f"‚úÖ Intelligence indicator: {indicator}")
                found_indicators.append(indicator)
            else:
                print(f"‚ùå Missing indicator: {indicator}")
        
        intelligence_score = len(found_indicators) / len(intelligence_indicators)
        print(f"\nüìä Intelligence completeness: {intelligence_score*100:.1f}%")
        return {"score": intelligence_score, "indicators": found_indicators}
    else:
        print(f"‚ùå Mutation intelligence file missing: {mutation_file}")
        return {"score": 0, "indicators": []}

def verify_github_workflow():
    """Test 4: Verify GitHub workflow integration"""
    print("\n‚ö° LAYER 4: GitHub Workflow Verification")
    print("-" * 50)
    
    workflow_file = '.github/workflows/patch_libffi_ci.yml'
    if os.path.exists(workflow_file):
        with open(workflow_file, 'r') as f:
            content = f.read()
        
        critical_elements = [
            'libltdl7-dev libtool autoconf automake m4',
            'patches/fix_libffi_autoconf.sh',
            'python-for-android',
            'm4_pattern_allow',
            'LT_SYS_SYMBOL_USCORE'
        ]
        
        found_elements = []
        for element in critical_elements:
            if element in content:
                print(f"‚úÖ Workflow element: {element}")
                found_elements.append(element)
            else:
                print(f"‚ùå Missing element: {element}")
        
        workflow_score = len(found_elements) / len(critical_elements)
        print(f"\nüìä Workflow completeness: {workflow_score*100:.1f}%")
        return {"score": workflow_score, "elements": found_elements}
    else:
        print(f"‚ùå GitHub workflow missing: {workflow_file}")
        return {"score": 0, "elements": []}

def verify_dual_reality_logging():
    """Test 5: Verify dual-reality logging system"""
    print("\nüé≠ LAYER 5: Dual-Reality Logging Verification")
    print("-" * 50)
    
    phantom_logger = 'phantom_logger.py'
    if os.path.exists(phantom_logger):
        with open(phantom_logger, 'r') as f:
            content = f.read()
        
        dual_reality_features = [
            'external_log',
            'internal_log',
            'signature',
            'deception',
            'cryptographic'
        ]
        
        found_features = []
        for feature in dual_reality_features:
            if feature.lower() in content.lower():
                print(f"‚úÖ Dual-reality feature: {feature}")
                found_features.append(feature)
            else:
                print(f"‚ùå Missing feature: {feature}")
        
        reality_score = len(found_features) / len(dual_reality_features)
        print(f"\nüìä Dual-reality capability: {reality_score*100:.1f}%")
        return {"score": reality_score, "features": found_features}
    else:
        print(f"‚ùå Phantom logger missing: {phantom_logger}")
        return {"score": 0, "features": []}

def generate_immunity_report():
    """Generate comprehensive immunity verification report"""
    print("\n" + "=" * 70)
    print("üõ°Ô∏è COMPLETE LIBFFI IMMUNITY VERIFICATION REPORT")
    print("=" * 70)
    
    # Run all verification layers
    deps_result = verify_system_dependencies()
    scripts_result = verify_patch_scripts()
    mutation_result = verify_mutation_intelligence()
    workflow_result = verify_github_workflow()
    logging_result = verify_dual_reality_logging()
    
    # Calculate overall immunity score
    scores = [
        len([v for v in deps_result.values() if v == "available"]) / len(deps_result),
        len([r for r in scripts_result.values() if r["status"] == "present"]) / len(scripts_result),
        mutation_result["score"],
        workflow_result["score"],
        logging_result["score"]
    ]
    
    overall_immunity = sum(scores) / len(scores)
    
    # Generate final report
    report = {
        "timestamp": datetime.now().isoformat() + "Z",
        "immunity_verification": {
            "overall_score": overall_immunity,
            "layer_scores": {
                "system_dependencies": scores[0],
                "patch_scripts": scores[1], 
                "mutation_intelligence": scores[2],
                "github_workflow": scores[3],
                "dual_reality_logging": scores[4]
            },
            "immunity_status": "IMMUNE" if overall_immunity >= 0.9 else "PARTIAL" if overall_immunity >= 0.7 else "VULNERABLE",
            "libffi_protection": "COMPLETE" if overall_immunity >= 0.9 else "INCOMPLETE"
        }
    }
    
    print(f"\nüéØ OVERALL LIBFFI IMMUNITY SCORE: {overall_immunity*100:.1f}%")
    print(f"üõ°Ô∏è PROTECTION STATUS: {report['immunity_verification']['immunity_status']}")
    print(f"‚ö° AUTOCONF FAILURE PROTECTION: {report['immunity_verification']['libffi_protection']}")
    
    if overall_immunity >= 0.9:
        print("\n‚úÖ SYSTEM IS FULLY IMMUNE TO LIBFFI AUTOCONF FAILURES")
        print("‚úÖ LT_SYS_SYMBOL_USCORE errors will be automatically prevented")
        print("‚úÖ All defensive layers operational with high confidence")
    elif overall_immunity >= 0.7:
        print("\n‚ö†Ô∏è SYSTEM HAS PARTIAL IMMUNITY - SOME LAYERS NEED ATTENTION")
    else:
        print("\n‚ùå SYSTEM VULNERABLE - MULTIPLE LAYERS NEED IMPLEMENTATION")
    
    return report

if __name__ == "__main__":
    print("üé≠ PHANTOM CORE LIBFFI IMMUNITY VERIFICATION")
    print("Complete defensive system validation")
    print("Time:", datetime.now().isoformat())
    print("")
    
    report = generate_immunity_report()
    
    # Save verification report
    with open('logs/libffi_immunity_verification.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nüìä Verification report saved: logs/libffi_immunity_verification.json")